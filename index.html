<!DOCTYPE html>
<html>
<head>
    <title>PokePhonics Inference</title>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest/dist/tf.min.js"></script>
</head>
<body>
    <h1>PokePhonics Browser Inference</h1>
    <input type="text" id="inputWord" value="Pikachu" placeholder="Enter PokÃ©mon Name">
    <button onclick="runInference()">Generate IPA</button>
    <p><strong>Output:</strong> <span id="output">...</span></p>

    <script>
        // --- CONFIGURATION ---
        // In the browser, these are URLs relative to the HTML file
        const MODEL_URL = './tfjs_model/model.json';
        const VOCAB_URL = './vocab.json';
        const MAX_LEN = 40;
        const BEAM_WIDTH = 5;

        let model = null;
        let vocab = null;
        let invVocab = null;

        // --- SETUP ---
        async function loadResources() {
            if (model) return; // Already loaded

            console.log("Loading model...");
            // BROWSER DIFFERENCE 1: automatic fetching
            // tf.loadGraphModel automatically uses 'fetch' in the browser.
            // No fileLoader or custom handlers needed!
            model = await tf.loadGraphModel(MODEL_URL);

            console.log("Loading vocab...");
            const vocabResp = await fetch(VOCAB_URL);
            vocab = await vocabResp.json();
            invVocab = Object.fromEntries(Object.entries(vocab).map(([k, v]) => [v, k]));

            console.log("Ready!");
        }

        async function runInference() {
            await loadResources();

            const word = document.getElementById('inputWord').value;
            const outputSpan = document.getElementById('output');
            outputSpan.innerText = "Thinking...";

            // Run in a slight delay to let the UI update
            setTimeout(async () => {
                const ipa = await decodeBeamBatched(word, "<");
                outputSpan.innerText = ipa;
            }, 10);
        }

        // --- BEAM SEARCH LOGIC (COPIED FROM YOUR NODE SCRIPT) ---
        // The logic is IDENTICAL. I only removed the 'model', 'vocab', 'invVocab' args
        // since they are global in this script.
        async function decodeBeamBatched(word, taskToken) {
            return tf.tidy(() => {
                const fullText = taskToken + word.toLowerCase();
                const START_TOKEN = vocab["["];
                const STOP_TOKEN = vocab["]"];
                const PAD_TOKEN = vocab["[PAD]"];

                let encIds = fullText.split('').map(c => vocab[c] || 0).slice(0, MAX_LEN);
                while (encIds.length < MAX_LEN) encIds.push(PAD_TOKEN);

                const encTensor = tf.tensor2d(Array(BEAM_WIDTH).fill(encIds), [BEAM_WIDTH, MAX_LEN], 'float32');
                let scores = tf.tensor1d([0.0, ...Array(BEAM_WIDTH - 1).fill(-1e9)]);
                let sequences = tf.fill([BEAM_WIDTH, 1], START_TOKEN, 'int32');

                let finishedSeqs = [];
                let finishedScores = [];

                for (let i = 0; i < MAX_LEN - 1; i++) {
                    const currLen = sequences.shape[1];
                    const padSize = (MAX_LEN - 1) - currLen;

                    let decInput = sequences.cast('float32');
                    if (padSize > 0) {
                        decInput = decInput.pad([[0, 0], [0, padSize]], PAD_TOKEN);
                    }

                    // Named inputs work perfectly in browser WebGL backend too
                    const inputs = { 'enc_in': encTensor, 'dec_in': decInput };

                    let preds = model.execute(inputs);
                    if (Array.isArray(preds)) preds = preds[0];

                    const nextTokenLogits = preds.gather([currLen - 1], 1).reshape([BEAM_WIDTH, -1]);
                    const logProbs = tf.logSoftmax(nextTokenLogits);

                    const candidateScores = scores.expandDims(1).add(logProbs);
                    const flatScores = candidateScores.reshape([-1]);
                    const {values: topKScores, indices: topKIndices} = tf.topk(flatScores, BEAM_WIDTH);

                    const vocabSize = logProbs.shape[1];
                    const beamIndices = topKIndices.div(tf.scalar(vocabSize, 'int32')).cast('int32');
                    const tokenIndices = topKIndices.mod(tf.scalar(vocabSize, 'int32')).cast('int32');

                    // SYNC: In browser, arraySync() causes a UI thread block.
                    // For production, you might want to use await .array() and make the function async
                    // to keep the UI responsive, but sync is fine for testing.
                    const bIdxArr = beamIndices.arraySync();
                    const tIdxArr = tokenIndices.arraySync();
                    const sArr = topKScores.arraySync();
                    const seqsArr = sequences.arraySync();

                    const nextSeqs = [];
                    const nextScoresArr = [];

                    for (let k = 0; k < BEAM_WIDTH; k++) {
                        const bIdx = bIdxArr[k];
                        const token = tIdxArr[k];
                        const score = sArr[k];

                        if (token === STOP_TOKEN) {
                            finishedSeqs.push(seqsArr[bIdx]);
                            finishedScores.push(score);
                            nextSeqs.push([...seqsArr[bIdx], PAD_TOKEN]);
                            nextScoresArr.push(-1e9);
                        } else {
                            nextSeqs.push([...seqsArr[bIdx], token]);
                            nextScoresArr.push(score);
                        }
                    }

                    sequences = tf.tensor2d(nextSeqs, [BEAM_WIDTH, nextSeqs[0].length], 'int32');
                    scores = tf.tensor1d(nextScoresArr);

                    if (Math.max(...nextScoresArr) < -1e8) break;
                }

                let finalSeq;
                if (finishedSeqs.length > 0) {
                    const bestIdx = finishedScores.indexOf(Math.max(...finishedScores));
                    finalSeq = finishedSeqs[bestIdx];
                } else {
                    const bestIdx = scores.argMax().dataSync()[0];
                    finalSeq = sequences.arraySync()[bestIdx];
                }

                return finalSeq
                    .filter(id => id !== START_TOKEN && id !== STOP_TOKEN && id !== PAD_TOKEN)
                    .map(id => invVocab[id])
                    .join('');
            });
        }

        // Auto-load on page open
        loadResources();
    </script>
</body>
</html>